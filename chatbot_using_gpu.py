# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_5beQ0QSvlI3ab3LpQKQHpRfshsKxHLX
"""

!pip install transformers torch pandas

from google.colab import files
files.upload()  # Upload kaggle.json

from google.colab import drive
drive.mount('/content/drive')  # Follow the authorization steps

from google.colab import drive
drive.mount('/content/drive')
import pandas as pd
df = pd.read_csv('/content/drive/MyDrive/Students_Grading_Dataset.csv')
print(df.head())

!pip install transformers torch sentence-transformers

import torch
from transformers import pipeline

# Check GPU availability
device = 0 if torch.cuda.is_available() else -1
print(f"Using device: {'GPU' if device == 0 else 'CPU'}")

# Load BERT Q&A model (GPU-accelerated)
qa_pipeline = pipeline(
    "question-answering",
    model="bert-large-uncased-whole-word-masking-finetuned-squad",
    device=device
)

# Create context strings from your DataFrame
df['context'] = df.apply(lambda row: ' '.join([str(x) for x in row]), axis=1)
contexts = df['context'].tolist()

def answer_question(question, top_k=3):
    answers = []
    for context in contexts[:1000]:  # Limit to first 1000 rows for speed
        result = qa_pipeline(question=question, context=str(context))
        answers.append({
            'answer': result['answer'],
            'score': result['score'],
            'context': context[:200] + "..."  # Truncated for display
        })

    # Return top answers by confidence score
    return sorted(answers, key=lambda x: x['score'], reverse=True)[:top_k]

!pip install transformers torch sentence-transformers --quiet
import torch
from transformers import pipeline
from sentence_transformers import SentenceTransformer
import pandas as pd
import time

# Load and clean data
from google.colab import drive
drive.mount('/content/drive')
df = pd.read_csv('/content/drive/MyDrive/Students_Grading_Dataset.csv')
print(df.head())

# Remove rows with duplicate first+last names (keeping first occurrence)
df = df.drop_duplicates(subset=['First_Name', 'Last_Name'], keep='first')

# Verify duplicates removed
print(f"Removed duplicates. New dataset size: {len(df)}")
print(df[['First_Name', 'Last_Name']].value_counts().head())  # Show name counts

# GPU Setup
device = 0 if torch.cuda.is_available() else -1
encoder = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')
qa_pipeline = pipeline(
    "question-answering",
    model="distilbert-base-uncased-distilled-squad",
    device=device,
    torch_dtype=torch.float16
)

def prepare_contexts(df):
    """Create enhanced contexts with unique student identifiers"""
    contexts = []
    for _, row in df.iterrows():
        context = (
            f"STUDENT RECORD || ID: {row['Student_ID']} || "
            f"Full Name: {row['First_Name']} {row['Last_Name']} || "
            f"Department: {row['Department']} || "
            f"Academic: Midterm({row['Midterm_Score']}), Final({row['Final_Score']}), "
            f"Total({row['Total_Score']}), Grade({row['Grade']}) || "
            f"Attendance: {row['Attendance (%)']}% || "
            f"Study Habits: {row['Study_Hours_per_Week']} hrs/week || "
            f"Background: Parent Education({row['Parent_Education_Level']}), "
            f"Income({row['Family_Income_Level']})"
        )
        contexts.append(context)
    return contexts

contexts = prepare_contexts(df)
context_embeddings = encoder.encode(contexts, convert_to_tensor=True)

def get_best_answer(question):
    """Enhanced answer retrieval with duplicate handling"""
    question_embed = encoder.encode(question, convert_to_tensor=True)
    scores = torch.mm(question_embed.unsqueeze(0), context_embeddings.T)[0]
    best_idx = torch.argmax(scores).item()
    result = qa_pipeline(question=question, context=contexts[best_idx])

    return {
        'answer': result['answer'],
        'confidence': result['score'],
        'student_id': df.iloc[best_idx]['Student_ID'],
        'full_name': f"{df.iloc[best_idx]['First_Name']} {df.iloc[best_idx]['Last_Name']}",
        'department': df.iloc[best_idx]['Department']
    }

def chatbot():
    print("\nüéì Unique Student Chatbot (Type 'quit' to exit)")
    print("Now with duplicate names removed for accurate results!\n")

    while True:
        question = input("\nYour question: ").strip()
        if question.lower() in ['quit', 'exit']:
            break

        start = time.time()
        try:
            answer = get_best_answer(question)
            print(f"\n‚è±Ô∏è {time.time()-start:.2f}s | Confidence: {answer['confidence']:.2f}")
            print(f"\nüë§ {answer['full_name']} (ID: {answer['student_id']})")
            print(f"üè´ Department: {answer['department']}")
            print(f"üí° Answer: {answer['answer']}")

            # Show similar names as disclaimer if question contains a name
            if any(name.lower() in question.lower()
                  for name in df['First_Name'].tolist() + df['Last_Name'].tolist()):
                similar = df[
                    (df['First_Name'].str.lower().isin(question.lower().split())) |
                    (df['Last_Name'].str.lower().isin(question.lower().split()))
                ].shape[0]
                if similar > 1:
                    print(f"\n‚ÑπÔ∏è Note: {similar} students share parts of this name")

        except Exception as e:
            print(f"\n‚ùå Error: {str(e)}")

# Run
chatbot()